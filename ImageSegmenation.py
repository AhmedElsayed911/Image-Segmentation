# -*- coding: utf-8 -*-
"""Assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nsNESuHlMHQ0IhuBpnbbBbPnStN1PIPh
"""

from matplotlib import image
import numpy as np
import requests
import tarfile
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
from matplotlib.image import imread
import scipy.io
import scipy.misc
import cv2
from glob import glob
from PIL import Image
import math
from math import log
from copy import deepcopy
from sklearn import preprocessing
from sklearn.metrics import f1_score
from sklearn.neighbors import kneighbors_graph
from scipy.spatial.distance import cdist 
from sklearn.metrics.cluster import completeness_score
from sklearn import metrics

"""# 1-"""

url = 'http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz'
r = requests.get(url, allow_redirects=True)
open('BSR_bsds500.tgz', 'wb').write(r.content)
filename = "BSR_bsds500.tgz"
tf = tarfile.open(filename)
tf.extractall('/content/data')

tr_img = []
te_img = []
v_img = []

tr_gt = []
te_gt = []
v_gt = []

train_Names=glob('/content/data/BSR/BSDS500/data/images/train/*.jpg')
test_Names=glob('/content/data/BSR/BSDS500/data/images/test/*.jpg')
val_Names=glob('/content/data/BSR/BSDS500/data/images/val/*.jpg')

train_Names=sorted(train_Names)
test_Names=sorted(test_Names)
val_Names=sorted(val_Names)

train_GT=glob('/content/data/BSR/BSDS500/data/groundTruth/train/*.mat')
test_GT=glob('/content/data/BSR/BSDS500/data/groundTruth/test/*.mat')
val_GT=glob('/content/data/BSR/BSDS500/data/groundTruth/val/*.mat')

train_GT=sorted(train_GT)
test_GT=sorted(test_GT)
val_GT=sorted(val_GT)


## for training 
for k in range(len(train_Names)):
  tr_img.append(imread(train_Names[k]))
  # returns a directory which have "groundtruth" as a key to a list of arrays 
  GT_Tr_D = scipy.io.loadmat(train_GT[k])
  data=GT_Tr_D['groundTruth'][0][:]
  temp = [] 

  for j in range(data.size):
    temp.append(np.ravel(data[j][0][0][0]))
  temp=np.array(temp) 
  tr_gt.append(temp)

tr_img=np.array(tr_img)


#### for testing 
for k in range(len(test_Names)):
  te_img.append(imread(train_Names[k]))
  GT_Ts_D = scipy.io.loadmat(test_GT[k])
  data=GT_Ts_D['groundTruth'][0][:]
  temp = [] 

  for j in range(data.size):
    temp.append(np.ravel(data[j][0][0][0]))
  temp=np.array(temp) 
  te_gt.append(temp)
  

te_img=np.array(te_img)

#### for evaluation 
for k in range(len(val_Names)):
  v_img.append(imread(train_Names[k]))
  GT_V_D = scipy.io.loadmat(val_GT[k])
  data=GT_V_D['groundTruth'][0][:]
  temp = [] 

  for j in range(data.size):
    temp.append(np.ravel(data[j][0][0][0]))
  temp=np.array(temp) 
  v_gt.append(temp)

v_img=np.array(v_img)

img=deepcopy(tr_img)
for i in range (tr_img.shape[0]):
  img[i]=img[i].reshape(-1, img[i].shape[-1])
tr_img[0].shape

"""# 2-"""

def ShowImageAndGroundTruth(images,groundtruth,index):
  plt.imshow(images[index])
  plt.show()
  for j in range(len(groundtruth[index])):
    if images[index].shape[0]==481:
      plt.imshow(groundtruth[index][j].reshape((481, 321)))
      plt.show()
    else : 
      plt.imshow(groundtruth[index][j].reshape((321, 481)))
      plt.show()

ShowImageAndGroundTruth(tr_img,tr_gt,0)

"""#3-  K-means"""

def Kmeans (data,K=3,maxitr=200):
  data=data.reshape(-1, data.shape[-1])
  n = data.shape[0]
  c = data.shape[1]
  idx = np.random.choice(len(data), K, replace=False)
  centroids = data[idx, :]
  numofitr=0
  error=1000
  while error > 0.001 and numofitr<maxitr:
    dist=cdist(data, centroids ,'euclidean') 
    numofitr+=1
    cluster=np.argmin(dist,axis=1)
    Newcentroids=np.zeros((K,c))
    for i in range(K):
      if data[cluster==i].size>1:
        Newcentroids[i]=np.mean(data[cluster==i],axis=0)
      else:
        Newcentroids[i]=centroids[i]
    error = np.linalg.norm(Newcentroids - centroids)
    centroids = deepcopy(Newcentroids)
  cluster=cluster+1
  return centroids,cluster

def numofclasses(groundtruth,index):
  num=np.zeros(len(groundtruth[index]))
  for j in range(len(groundtruth[index])):
    num[j]=max(groundtruth[index][j])
  return num

fscore=np.zeros(5)
ConEntropy=np.zeros(5)
Ent=np.zeros(5)
K=[3,5,7,9,11]
nf=np.zeros(5)
for i in range(img.shape[0]):
  for j in range(5):
    centroids,cluster=Kmeans(tr_img[i],K[j])
    index = np.where(numofclasses(tr_gt,i) == K[j])[0]
    if index.size==1:
      GT=tr_gt[i][index]
      GT=GT.reshape(154401,1)
      fscore[j]+=f1_score(cluster, GT, average='macro',labels=np.unique(cluster))
      ConEntropy[j]+=Entropy(cluster,GT)
      #GT2=np.squeeze(GT)
      #cl2=np.squeeze(cluster)
      #Ent[j]+=metrics.homogeneity_completeness_v_measure(GT2,cl2)[2]
      nf[j]+=1
for i in range(5):
  if nf[i]>0:
    fscore[i]=(fscore[i])/(nf[i])
    ConEntropy[i]=(ConEntropy[i])/(nf[i])
    #Ent[i]=(Ent[i])/(nf[i])

print(fscore)
print(ConEntropy)
print(fscore.shape)

"""### F_score"""

def F_score(C,groundtruth,K):
  nt=C.shape[0]
  x=np.zeros((K,K))
  for i in range(1,K+1):
    u=groundtruth[(C==i)]
    for j in range(1,K+1):
      h= np.count_nonzero(u == j)
      x[i-1][j-1]=h
  n=np.sum(x,axis=1)
  per=np.zeros(K)
  for i in range(K):
    per[i]=(1/n[i])*max(x[i])
  T=np.sum(x.T,axis=1)
  F=np.zeros(K)
  rec=np.zeros(K)
  for i in range(K):
    rec[i]=(1/T[np.argmax(x[i])])*max(x[i])
  for i in range(K):
    F[i]=(2*per[i]*rec[i])/(per[i]+rec[i])
  FT=np.sum(F)/K
  return FT

numofclasses(tr_gt,9)

"""### entropy"""

def logfunc(x,base):
  if x==0:
    return 0
  else:
    return log(x,base)

def Entropy(C,groundtruth,base=2):
  K=max(groundtruth)
  nt=C.shape[0]
  x=np.zeros((K,K))
  for i in range(1,K+1):
    u=groundtruth[(C==i)]
    for j in range(1,K+1):
      h= np.count_nonzero(u == j)
      x[i-1][j-1]=h
  n=np.sum(x,axis=1)
  H=np.zeros(K)
  HT=0
  for i in range(K):
    for j in range(K):
      H[i]+=-(x[i][j]/n[i])*(logfunc(x[i][j]/n[i],base))
  HT+=(n[i]/nt)*H[i]
  return HT

"""# 4-

## a-
"""

index=np.random.randint(200)
center,cluster=Kmeans(tr_img[index],5)
print("After K-means")
if tr_img[index].shape[0]==481:
  plt.imshow(cluster.reshape((481, 321)))
  plt.show()
else :
  plt.imshow(cluster.reshape((321, 481)))
  plt.show() 
print("Image and her Groud truth")
ShowImageAndGroundTruth(tr_img,tr_gt,index)

index=np.random.randint(200)
center,cluster=Kmeans(tr_img[index],5)
print("After K-means")
if tr_img[index].shape[0]==481:
  plt.imshow(cluster.reshape((481, 321)))
  plt.show()
else :
  plt.imshow(cluster.reshape((321, 481)))
  plt.show() 
print("Image and her Groud truth")
ShowImageAndGroundTruth(tr_img,tr_gt,index)

index=np.random.randint(200)
center,cluster=Kmeans(tr_img[index],5)
print("After K-means")
if tr_img[index].shape[0]==481:
  plt.imshow(cluster.reshape((481, 321)))
  plt.show()
else :
  plt.imshow(cluster.reshape((321, 481)))
  plt.show() 
print("Image and her Groud truth")
ShowImageAndGroundTruth(tr_img,tr_gt,index)

index=np.random.randint(200)
center,cluster=Kmeans(tr_img[index],5)
print("After K-means")
if tr_img[index].shape[0]==481:
  plt.imshow(cluster.reshape((481, 321)))
  plt.show()
else :
  plt.imshow(cluster.reshape((321, 481)))
  plt.show() 
print("Image and her Groud truth")
ShowImageAndGroundTruth(tr_img,tr_gt,index)

index=np.random.randint(200)
center,cluster=Kmeans(tr_img[index],5)
print("After K-means")
if tr_img[index].shape[0]==481:
  plt.imshow(cluster.reshape((481, 321)))
  plt.show()
else :
  plt.imshow(cluster.reshape((321, 481)))
  plt.show() 
print("Image and her Groud truth")
ShowImageAndGroundTruth(tr_img,tr_gt,index)

"""## b-"""

def Ncut (data,kn=3,K=3):
  data=data.reshape(-1, data.shape[-1])
  sim = kneighbors_graph(data, kn, mode='connectivity', include_self=False).toarray()
  print(sim.shape)
  Delta = np.diag(np.sum(sim, axis=1))
  L = Delta - sim
  La = np.dot(np.linalg.inv(Delta), L)
  eigen_values, eigen_vectors = np.linalg.eig(La)
  eigen_values, eigen_vectors = np.real(eigen_values), np.real(eigen_vectors)
  idx = np.argsort(eigen_values)
  eigen_values = eigen_values[idx]
  eigen_vectors = eigen_vectors[:,idx]



  U = eigen_vectors[:,range(K)]
  Y = preprocessing.normalize(eigen_vectors, norm='l2')
  return Kmeans(Y,K)

import cv2

kn=5
K=5
x=deepcopy(tr_img[0])

# x.resize((100,100))

x=cv2.resize(x, (100,100))

plt.imshow(x)
data=x
data=data.reshape(-1, data.shape[-1])
print(data.shape)
n=data.shape[0]

matrix 0 x 0 10000 x 100000

first 0 1 2 3 4 5 6 

Rbf kernal on the dismilartiy matrix 



# sim = np.zeros((n,n))
# Delta = np.diag(np.sum(sim, axis=1))
# L = Delta - sim
# La = np.dot(np.linalg.inv(Delta), L)
# eigen_values, eigen_vectors = np.linalg.eig(La)
# eigen_values, eigen_vectors = np.real(eigen_values), np.real(eigen_vectors)
# idx = np.argsort(eigen_values)
# eigen_values = eigen_values[idx]
# eigen_vectors = eigen_vectors[:,idx]
# U = eigen_vectors[:,range(K)]
# Y = preprocessing.normalize(eigen_vectors, norm='l2')

#index=np.random.randint(200)
from sklearn.cluster import SpectralClustering
from sklearn.cluster import spectral_clustering

index=4
img=deepcopy(tr_img[index])
img=cv2.resize(img, (100,100))

# images = []
# images.append(np.ravel(img[:,:,0]))
# images.append(np.ravel(img[:,:,1]))
# images.append(np.ravel(img[:,:,2]))
# images = np.array(images)
img=img.reshape(-1, img.shape[-1])
sim = kneighbors_graph(img, 5, mode='connectivity', include_self=False).toarray()

labels = spectral_clustering(sim, n_clusters=5, random_state=0, n_init=10,assign_labels='kmeans')
plt.imshow(labels.reshape((100, 100)))
# center,cluster=Ncut(img,5,5)
# clustering = SpectralClustering(n_clusters=5,assign_labels="kmeans",random_state=8,affinity='nearest_neighbors',n_neighbors =5).fit(img)

# plt.imshow(clustering.labels_.reshape((100, 100)))
# print("After Normalized-cut")

# plt.show()
# print("Image and her Groud truth")
# ShowImageAndGroundTruth(tr_img,tr_gt,index)

plt.imshow(labels.reshape((100, 100)))
plt.show()
ShowImageAndGroundTruth(tr_img,tr_gt,index)